{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Hands-On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cv2 as cv\n",
    "except ImportError:\n",
    "    %pip install opencv-python\n",
    "    import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Mat Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mat structure is the fundamental data structure in OpenCV. It is a multi-dimensional array that can store images, matrices, and vectors. The Mat structure is the primary container for all OpenCV objects. It is a template class that can store any type of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "im: cv.Mat = cv.imread(\"./images/monarch.png\", cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if image is loaded fine\n",
    "if im is None:\n",
    "    print(\"Error opening image\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "cv.imshow(\"Image\", im)\n",
    "cv.waitKey(0)  # Wait for a key press indefinitely\n",
    "cv.destroyAllWindows()  # Close the window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image1.png](./attachments/image1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we are going to create a 64x64 empty picture. The original picture is 256x256. We'll resize the original picture to 64x64 and display it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load an image\n",
    "image: cv.Mat = cv.imread(\"./images/peppers-256.png\", cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if image is loaded fine\n",
    "if image is None:\n",
    "    print(\"Error opening image\")\n",
    "    exit(1)\n",
    "\n",
    "# Create an empty image\n",
    "croppedimage = np.zeros((64, 64), dtype=image.dtype)\n",
    "\n",
    "# Crop the image with for loops by taking every 4th pixel \n",
    "for i in range(64):\n",
    "    for j in range(64):\n",
    "        croppedimage[i, j] = image[i*4, j*4]\n",
    "\n",
    "# Display the images\n",
    "cv.imshow(\"Image\", image)\n",
    "cv.imshow(\"Cropped image\", croppedimage)\n",
    "cv.waitKey(0)  \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image2.png](./attachments/image2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resized imaged is still recognizable, but the quality is not as good as the original image. It looks pixelated and the edges are not as sharp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying convolutional filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to apply filters using the `filter2D` function. This function takes the input image and the kernel as arguments. \n",
    "We'll use the `peppers-512.png` image as input and apply different filters to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imk = cv.imread(\"./images/peppers-512.png\", cv.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first kernel is defined as:\n",
    "$$\n",
    "\\frac{1}{16} \\begin{pmatrix}\n",
    "    1 & 2 & 1 \\\\\n",
    "    2 & 4 & 2 \\\\\n",
    "    1 & 2 & 1\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the kernel\n",
    "kernel1 = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16\n",
    "\n",
    "# Apply the filter using filter2D\n",
    "imk1_filtered = cv.filter2D(imk, -1, kernel1)\n",
    "\n",
    "# Display the image\n",
    "cv.imshow(\"Image\", imk)\n",
    "cv.imshow(\"Filtered Image\", imk1_filtered)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image3.png](./attachments/image3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The applied filter is a Gaussian blur filter. It slightly blurs the output image. The edges are not as sharp as in the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second kernel is defined as:\n",
    "\n",
    "$$\n",
    "\\frac{1}{9} \\begin{pmatrix}\n",
    "    1 & 1 & 1 \\\\\n",
    "    1 & 1 & 1 \\\\\n",
    "    1 & 1 & 1\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the kernel\n",
    "kernel2 = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9\n",
    "\n",
    "# Apply the filter using filter2D\n",
    "imk2_filtered = cv.filter2D(imk, -1, kernel2)\n",
    "\n",
    "# Display the image\n",
    "cv.imshow(\"Image\", imk)\n",
    "cv.imshow(\"Filtered Image\", imk2_filtered)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image4.png](./attachments/image4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The applied filter is a box filter. It also slightly blurs the image and the edges are not as sharp as in the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third kernel is defined as:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "    1 & -3 & 1 \\\\\n",
    "    -3 & 9 & -3 \\\\\n",
    "    1 & -3 & 1\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the kernel\n",
    "kernel3 = np.array([[1, -3, 1], [-3, 9, -3], [1, -3, 1]])\n",
    "\n",
    "# Apply the filter using filter2D\n",
    "imk3_filtered = cv.filter2D(imk, -1, kernel3)\n",
    "\n",
    "# Display the image\n",
    "cv.imshow(\"Image\", imk)\n",
    "cv.imshow(\"Filtered Image\", imk3_filtered)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image5.png](./attachments/image5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the filter is a sharpening filter. It enhances the edges of the image and makes them more pronounced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth kernel is defined as:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "    -1 & 0 & 1 \\\\\n",
    "    -2 & 0 & 2 \\\\\n",
    "    -1 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the kernel\n",
    "kernel4 = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "\n",
    "# Apply the filter using filter2D\n",
    "imk4_filtered = cv.filter2D(imk, -1, kernel4)\n",
    "\n",
    "# Display the image\n",
    "cv.imshow(\"Image\", imk)\n",
    "cv.imshow(\"Filtered Image\", imk4_filtered)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image6.png](./attachments/image6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Sobel filter for detecting horizontal edges. It emphasizes vertical intensity changes in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fifth kernel is defined as:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "    0 & -1 & -1 \\\\\n",
    "    1 & 0 & -1 \\\\\n",
    "    1 & 1 & 0\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the kernel\n",
    "kernel5 = np.array([[0, -1, -1], [1, 0, -1], [1, 1, 0]])\n",
    "\n",
    "# Apply the filter using filter2D\n",
    "imk5_filtered = cv.filter2D(imk, -1, kernel5)\n",
    "\n",
    "# Display the image\n",
    "cv.imshow(\"Image\", imk)\n",
    "cv.imshow(\"Filtered Image\", imk5_filtered)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image7.png](./attachments/image7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Kirsch compass kernel, specifically for edge detection. This kernel detects edges in a specific diagonal direction (bottom-left to top-right). We can see that because on the filtered image the edges are highlighted in that direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sixth kernel is defined as:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "    0 & 1 & 0 \\\\\n",
    "    1 & -4 & 1 \\\\\n",
    "    0 & 1 & 0\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the kernel\n",
    "kernel5 = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]]) \n",
    "\n",
    "# Apply the filter using filter2D\n",
    "imk5_filtered = cv.filter2D(imk, -1, kernel5)\n",
    "\n",
    "# Display the image\n",
    "cv.imshow(\"Image\", imk)\n",
    "cv.imshow(\"Filtered Image\", imk5_filtered)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image8.png](./attachments/image8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Laplacian filter, commonly used for edge detection. It highlights regions of rapid intensity change by approximating the second derivative of the image, detecting edges regardless of direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this part is to manipulate the images pixel by pixel and not to use OpenCV functions. We'll therefore implement the dilation and erosion operations by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 kernels, rectangle, cross and ellipse\n",
    "\n",
    "\n",
    "Rectangle (kernel1):\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "    1 & 1 & 1 \\\\\n",
    "    1 & 1 & 1 \\\\\n",
    "    1 & 1 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Cross (kernel2):\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "    0 & 1 & 0 \\\\\n",
    "    1 & 1 & 1 \\\\\n",
    "    0 & 1 & 0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Ellipse (kernel3):\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "    0 & 1 & 1 & 0\\\\\n",
    "    1 & 1 & 1 & 1\\\\\n",
    "    0 & 1 & 1 & 0\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./images/peppers-512.png\", cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if image is loaded fine\n",
    "if im is None:\n",
    "    print(\"Error opening image\")\n",
    "    exit(1)\n",
    " \n",
    "# Create a binary image\n",
    "_, binary_img = cv.threshold(img, 127, 255, cv.THRESH_BINARY) # Thresholding consists of setting a pixel to a certain value if it is greater than a threshold.\n",
    "\n",
    "# Define the structuring elements (kernels)\n",
    "kernel1 = np.array([[1, 1, 1],\n",
    "                    [1, 1, 1],\n",
    "                    [1, 1, 1]], dtype=np.uint8)  # Rectangle\n",
    "\n",
    "kernel2 = np.array([[0, 1, 0],\n",
    "                    [1, 1, 1],\n",
    "                    [0, 1, 0]], dtype=np.uint8)  # Cross\n",
    "\n",
    "kernel3 = np.array([[0, 1, 1, 1, 0],\n",
    "                    [1, 1, 1, 1, 1],\n",
    "                    [0, 1, 1, 1, 0]], dtype=np.uint8)  # Ellipse\n",
    "\n",
    "# Function to apply erosion manually\n",
    "def apply_erosion(image, kernel):\n",
    "    eroded_img = np.zeros_like(image) # Create an empty image to store the eroded image\n",
    "    img_height, img_width = image.shape # Get the image dimensions\n",
    "    k_height, k_width = kernel.shape # Get the kernel dimensions\n",
    "    offset_y = k_height // 2 # Calculate the offset in the y direction in order to avoid the borders\n",
    "    offset_x = k_width // 2 # Calculate the offset in the x direction in order to avoid the borders\n",
    "\n",
    "    # Iterate through each pixel in the image, avoiding borders\n",
    "    for i in range(offset_y, img_height - offset_y):\n",
    "        for j in range(offset_x, img_width - offset_x):\n",
    "            match = True  # Flag to check if the kernel fits\n",
    "            # Iterate through the kernel\n",
    "            for m in range(k_height):\n",
    "                for n in range(k_width):\n",
    "                    # Only consider the kernel positions where the kernel has a '1' \n",
    "                    if kernel[m, n]:\n",
    "                        if image[i + m - offset_y, j + n - offset_x] == 0:\n",
    "                            match = False\n",
    "                            break  # No need to check further\n",
    "                if not match:\n",
    "                    break\n",
    "            if match:\n",
    "                eroded_img[i, j] = 255  # Set pixel to white if all positions match\n",
    "            else:\n",
    "                eroded_img[i, j] = 0    # Set pixel to black otherwise\n",
    "    return eroded_img\n",
    "\n",
    "# Apply erosion with each kernel\n",
    "eroded1_img = apply_erosion(binary_img, kernel1)\n",
    "eroded2_img = apply_erosion(binary_img, kernel2)\n",
    "eroded3_img = apply_erosion(binary_img, kernel3)\n",
    "\n",
    "# Display the results\n",
    "cv.imshow(\"Original Binary Image\", binary_img)\n",
    "cv.imshow(\"Eroded Image (Rectangle Kernel)\", eroded1_img)\n",
    "cv.imshow(\"Eroded Image (Cross Kernel)\", eroded2_img)\n",
    "cv.imshow(\"Eroded Image (Ellipse Kernel)\", eroded3_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image9.png](./attachments/image9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rectangle kernel\n",
    "\n",
    "The 3×3 rectangular kernel treats all pixels in the neighborhood equally. This results in a uniform erosion effect, shrinking white regions and expanding black regions.\n",
    "\n",
    "#### Cross kernel\n",
    "\n",
    "The cross-shaped kernel considers fewer pixels during erosion compared to the rectangle. This results in less erosion in diagonal directions, preserving thin diagonal structures while eroding horizontal and vertical edges more significantly.\n",
    "\n",
    "#### Ellipse kernel\n",
    "\n",
    "The ellipse-shaped kernel has more weight around the center and reduces erosion in diagonal and edge areas. This creates a smoother effect, retaining rounded features while eroding straight edges less aggressively than the rectangle kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary image\n",
    "_, binary_img = cv.threshold(img, 127, 255, cv.THRESH_BINARY)\n",
    "\n",
    "# Define the structuring elements (kernels)\n",
    "kernel1 = np.array([[1, 1, 1],\n",
    "                    [1, 1, 1],\n",
    "                    [1, 1, 1]], dtype=np.uint8)  # Rectangle\n",
    "\n",
    "kernel2 = np.array([[0, 1, 0],\n",
    "                    [1, 1, 1],\n",
    "                    [0, 1, 0]], dtype=np.uint8)  # Cross\n",
    "\n",
    "kernel3 = np.array([[0, 1, 0, 1, 0],\n",
    "                    [1, 1, 1, 1, 1],\n",
    "                    [0, 1, 1, 1, 0]], dtype=np.uint8)  # Ellipse-like\n",
    "\n",
    "# Function to apply dilation manually\n",
    "def apply_dilation(image, kernel):\n",
    "    dilated_img = np.zeros_like(image)\n",
    "    img_height, img_width = image.shape\n",
    "    k_height, k_width = kernel.shape\n",
    "    offset_y = k_height // 2\n",
    "    offset_x = k_width // 2\n",
    "\n",
    "    # Iterate through each pixel in the image, avoiding borders\n",
    "    for i in range(offset_y, img_height - offset_y):\n",
    "        for j in range(offset_x, img_width - offset_x):\n",
    "            found = False  # Flag to check if any kernel position matches\n",
    "            # Iterate through the kernel\n",
    "            for m in range(k_height):\n",
    "                for n in range(k_width):\n",
    "                    # Only consider the kernel positions where the kernel has a '1'\n",
    "                    if kernel[m, n]:\n",
    "                        if image[i + m - offset_y, j + n - offset_x] == 255:\n",
    "                            found = True\n",
    "                            break  # No need to check further\n",
    "                if found:\n",
    "                    break\n",
    "            if found:\n",
    "                dilated_img[i, j] = 255  # Set pixel to white if any position matches\n",
    "            else:\n",
    "                dilated_img[i, j] = 0    # Set pixel to black otherwise\n",
    "    return dilated_img\n",
    "\n",
    "# Apply dilation with each kernel\n",
    "dilated1_img = apply_dilation(binary_img, kernel1)\n",
    "dilated2_img = apply_dilation(binary_img, kernel2)\n",
    "dilated3_img = apply_dilation(binary_img, kernel3)\n",
    "\n",
    "# Display the results\n",
    "cv.imshow(\"Original Binary Image\", binary_img)\n",
    "cv.imshow(\"Dilated Image (Rectangle Kernel)\", dilated1_img)\n",
    "cv.imshow(\"Dilated Image (Cross Kernel)\", dilated2_img)\n",
    "cv.imshow(\"Dilated Image (Ellipse Kernel)\", dilated3_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image10.png](./attachments/image10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rectangle kernel\n",
    "\n",
    "Using the 3×3 rectangular kernel, dilation adds pixels uniformly around white regions in all directions. This makes objects thicker, fills small gaps, and connects nearby white regions.\n",
    "\n",
    "#### Cross kernel\n",
    "\n",
    "The cross-shaped kernel dilates primarily in vertical and horizontal directions, expanding less in diagonal directions. This results in a more restrained expansion compared to the rectangular kernel, preserving some structures.\n",
    "\n",
    "#### Ellipse kernel\n",
    "\n",
    "The ellipse-shaped kernel provides a smoother dilation effect, favoring rounded expansion around white regions. It avoids sharp corners, making the objects appear more rounded and natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening\n",
    "\n",
    "Opening is an erosion followed by a dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply opening (erosion followed by dilation)\n",
    "def apply_opening(image, kernel):\n",
    "    eroded_img = apply_erosion(image, kernel)\n",
    "    opened_img = apply_dilation(eroded_img, kernel)\n",
    "    return opened_img\n",
    "\n",
    "# Create a binary image\n",
    "_, binary_img = cv.threshold(img, 127, 255, cv.THRESH_BINARY)\n",
    "\n",
    "# Apply opening with the kernel\n",
    "opened_img = apply_opening(binary_img, kernel1)\n",
    "\n",
    "# Display the results\n",
    "cv.imshow(\"Original Binary Image\", binary_img)\n",
    "cv.imshow(\"Opened Image\", opened_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image11.png](./attachments/image11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the opening operation, the small white noise regions have been removed, and the boundaries of the white objects are smoothed. Opening is performed using erosion followed by dilation. This process eliminates smaller white areas while preserving the shape of larger objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing\n",
    "\n",
    "Closing is a dilation followed by an erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply closing (dilation followed by erosion)\n",
    "def apply_closing(image, kernel):\n",
    "    dilated_img = apply_dilation(image, kernel)\n",
    "    closed_img = apply_erosion(dilated_img, kernel)\n",
    "    return closed_img\n",
    "\n",
    "# Create a binary image\n",
    "_, binary_img = cv.threshold(img, 127, 255, cv.THRESH_BINARY)\n",
    "\n",
    "# Apply closing with the kernel\n",
    "closed_img = apply_closing(binary_img, kernel1)\n",
    "\n",
    "# Display the results\n",
    "cv.imshow(\"Original Binary Image\", binary_img)\n",
    "cv.imshow(\"Closed Image\", closed_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image12.png](./attachments/image12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the closing operation, the small black noise regions have been removed, and the boundaries of the white objects are smoothed. Closing is performed using dilation followed by erosion. This process eliminates smaller black areas while preserving the shape of larger objects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
